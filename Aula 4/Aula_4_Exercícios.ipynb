{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 4 - Exercícios",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3R2-_YuQT1r"
      },
      "source": [
        "# Regressão Softmax com dados do MNIST utilizando gradiente descendente estocástico por minibatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar um modelo de uma única camada linear no MNIST **sem** usar as seguintes funções do pytorch:\n",
        "\n",
        "- torch.nn.Linear\n",
        "- torch.nn.CrossEntropyLoss\n",
        "- torch.nn.NLLLoss\n",
        "- torch.nn.LogSoftmax\n",
        "- torch.optim.SGD\n",
        "- torch.utils.data.Dataloader\n",
        "- torch.utils.data.Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duwHoGhcjzfM"
      },
      "source": [
        "### Uso do Neptune.ai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSqIOO-2j5FL"
      },
      "source": [
        "! pip install neptune-client==0.9.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_mlpbWYkJh6"
      },
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "# Como obter seu API token do Neptune:\n",
        "# https://docs.neptune.ai/administration/security-and-privacy/how-to-find-and-set-neptune-api-token\n",
        "run = neptune.init(project='meu_usuario/meu_projeto', api_token='INSIRA O SEU TOKEN AQUI')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                      transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNF2XjLBWWe7",
        "outputId": "16e26faa-9140-4de3-e2f9-5683c1e30d7a"
      },
      "source": [
        "idx = torch.randperm(len(dataset_train_full))[:1000]\n",
        "x_train = dataset_train_full.data[idx]\n",
        "y_train = dataset_train_full.targets[idx]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 28, 28])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "# Escreva aqui o equivalente do código abaixo:\n",
        "# loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n",
        "\n",
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "# Escreva aqui o codigo para criar um modelo cujo o equivalente é: \n",
        "# model = torch.nn.Linear(28*28, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Inicialização dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "PARAMS = {'n_epochs': 30000,\n",
        "          'lr': 0.15,\n",
        "          'Loss': 'CrossEntropyLoss',\n",
        "          'optimizer': 'SGD',\n",
        "         }\n",
        "\n",
        "# Envia parametros para o Neptune\n",
        "run['parameters'] = PARAMS\n",
        "\n",
        "# Escreva aqui o equivalente de:\n",
        "# criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P"
      },
      "source": [
        "epochs = []\n",
        "losses = []\n",
        "\n",
        "total_trained_samples = 0\n",
        "for i in range(PARAMS['n_epochs']):\n",
        "    # Substitua aqui o loader_train de acordo com sua implementação do dataloader.\n",
        "    for x_train, y_train in loader_train:\n",
        "        # Transforma a entrada para uma dimensão\n",
        "        inputs = x_train.view(-1, 28 * 28)\n",
        "        # predict da rede\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        # Escreva aqui o código cujo o resultado é equivalente às 3 linhas abaixo:\n",
        "        # optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        losses.append(loss.item())\n",
        "        run['train/loss'].log(loss.item()) # Envia loss para o Neptune.\n",
        "\n",
        "    print('Época: {:d}/{:d}'.format(i,n_epochs-1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "print('Final loss:', loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dYK0nqsQT2U"
      },
      "source": [
        "### Visualizando gráfico de perda durante o treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:52.026752Z",
          "start_time": "2018-08-20T21:03:51.756518Z"
        },
        "id": "LIyUI6AHQT2V"
      },
      "source": [
        "plt.plot(epochs, losses)\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[:5 * n_batches_train +1:n_batches_train], losses[:5 * n_batches_train+1:n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fptnTktx_1rh"
      },
      "source": [
        "## Exercício \n",
        "\n",
        "Escreva um código que responda às seguintes perguntas:\n",
        "\n",
        "Qual é a amostra classificada corretamente, com maior probabilidade?\n",
        "\n",
        "Qual é a amostra classificada erradamente, com maior probabilidade?\n",
        "\n",
        "Qual é a amostra classificada corretamente, com menor probabilidade?\n",
        "\n",
        "Qual é a amostra classificada erradamente, com menor probabilidade?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzH8iMGt_1Rr"
      },
      "source": [
        "# Escreva o código aqui:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xmj1GWXUoNs"
      },
      "source": [
        "## Exercício Bonus\n",
        "\n",
        "Implemente um dataloader que aceite como parâmetro de entrada a distribuição probabilidade das classes que deverão compor um batch.\n",
        "Por exemplo, se a distribuição de probabilidade passada como entrada for:\n",
        "\n",
        "`[0.01, 0.01, 0.72, 0.2, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]`\n",
        "\n",
        "Em média, 72% dos exemplos do batch deverão ser da classe 2, 20% deverão ser da classe 3, e os demais deverão ser das outras classes.\n",
        "\n",
        "Mostre também que sua implementação está correta.\n"
      ]
    }
  ]
}